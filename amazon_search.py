# coding: shift-jis
from curses import KEY_MARK
import dataclasses
from decimal import ROUND_HALF_DOWN
from os import get_handle_inheritable
from socket import J1939_PGN_ADDRESS_CLAIMED
from tkinter import E
from bs4 import BeautifulSoup
import requests
import pandas as pd
import numpy as np
import csv

__author__ = "SakaiEiji"
__version__ = "1.0.0"
__date__    = "2019/05/25"

# ï¿½Aï¿½}ï¿½]ï¿½ï¿½ï¿½ÅŒï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½tï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ê‚Ìuï¿½ï¿½ï¿½iï¿½ï¿½ï¿½vï¿½Æuï¿½lï¿½iï¿½vï¿½ï¿½CSVï¿½É•Û‘ï¿½ï¿½ï¿½ï¿½ï¿½
def search_amazon(search_word):
    """
    ï¿½ï¿½ï¿½Í‚ï¿½ï¿½ê‚½ï¿½Lï¿½[ï¿½ï¿½ï¿½[ï¿½hï¿½ÌŒï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Êƒyï¿½[ï¿½Wï¿½ï¿½ï¿½ï¿½HTMLï¿½ï¿½ï¿½ï¿½Í‚ï¿½ï¿½ï¿½
    ï¿½ï¿½ï¿½iï¿½ï¿½ï¿½Aï¿½lï¿½iï¿½ï¿½CSVï¿½oï¿½Í‚ï¿½ï¿½ï¿½
    ï¿½È‚ï¿½ï¿½Aï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½yï¿½[ï¿½Wï¿½ÍƒTï¿½Cï¿½gï¿½Ì•ï¿½ï¿½×‚ğ“¥‚Ü‚ï¿½ï¿½u5ï¿½yï¿½[ï¿½Wï¿½vï¿½Ü‚Å‚Æ‚ï¿½ï¿½ï¿½

    @param search_word : this is a first param
    @raise keyError: raises an exception
    """

    # ï¿½Aï¿½}ï¿½]ï¿½ï¿½ï¿½Ìƒxï¿½[ï¿½Xï¿½Æ‚È‚ï¿½URL
    amazon = "https://www.amazon.co.jp"

    # ï¿½ó”’‚Å•ï¿½ï¿½ï¿½
    words = search_word.split(" ")
    # ï¿½æ“ªï¿½Lï¿½[ï¿½ï¿½ï¿½[ï¿½hï¿½æ“¾
    serch_words = words[0]
    # ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½2ï¿½Â–ÚˆÈ~ï¿½ÌƒLï¿½[ï¿½ï¿½ï¿½[ï¿½hï¿½ï¿½+ï¿½Å˜Aï¿½ï¿½
    for i in range(1, len(words)):
        serch_words = serch_words + "+" + words[i]
        dataclasses = {fghihfdigh gphreghpe}

    # ï¿½Xï¿½Nï¿½ï¿½ï¿½Cï¿½sï¿½ï¿½ï¿½Oï¿½ï¿½ï¿½ï¿½Tï¿½Cï¿½gï¿½ï¿½URLï¿½ï¿½ï¿½ì¬
    url =  amazon + "/s/ref=nb_sb_noss_2?__mk_ja_JP=ï¿½Jï¿½^ï¿½Jï¿½i&url=search-alias%3Daps&field-keywords=" + serch_words + "&rh=i%3Aaps%2Ck%3A" + serch_words

    # CSVï¿½Ìƒwï¿½bï¿½_ï¿½[ï¿½Éï¿½ï¿½ï¿½ï¿½İ‚ï¿½ï¿½é€ï¿½Ú‚ï¿½ï¿½ï¿½ï¿½Xï¿½gï¿½Åì¬
    columns = ["Name",  "Price"]
    # ï¿½zï¿½ñ–¼‚ï¿½ï¿½wï¿½è‚·ï¿½ï¿½
    df = pd.DataFrame(columns=columns)

    # ï¿½yï¿½[ï¿½Wï¿½Ôï¿½(1ï¿½yï¿½[ï¿½Wï¿½Ú‚ï¿½ï¿½ï¿½)
    page = 1

    #ï¿½@6ï¿½yï¿½[ï¿½Wï¿½ï¿½ï¿½ï¿½ï¿½Íuexceptï¿½vï¿½ï¿½ï¿½ï¿½ï¿½ï¿½
    try:

        #ï¿½@ï¿½Tï¿½Cï¿½gï¿½Ì•ï¿½ï¿½×‚ï¿½ï¿½lï¿½ï¿½ï¿½ï¿½ï¿½A1?5ï¿½yï¿½[ï¿½Wï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Jï¿½ï¿½Ô‚ï¿½
        while page < 6:

            # ï¿½ì¬ï¿½ï¿½ï¿½ï¿½URLï¿½ï¿½ï¿½ï¿½HTMLï¿½ï¿½ï¿½æ“¾
            response = requests.get(url).text
            # BeautifulSoupï¿½Ìï¿½ï¿½ï¿½ï¿½ï¿½
            soup = BeautifulSoup(response, 'html.parser')

            # htmlï¿½Ì‚Ç‚Ì•ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½æ“¾ï¿½ï¿½ï¿½é‚©ï¿½wï¿½ï¿½
            items = soup.find_all(attrs={'class':'s-result-item'})
            ite =   soup.find_all(attrs={'class':'s-result-item'})

            # ï¿½æ“¾ï¿½ï¿½ï¿½ï¿½ï¿½^ï¿½Oï¿½Sï¿½ï¿½1ï¿½Â‚ï¿½ï¿½Âï¿½ï¿½ï¿½
            for item in items:

                # ï¿½ï¿½ï¿½iï¿½ï¿½ï¿½Ìƒ^ï¿½Oï¿½æ“¾r
                name = item.find("span", {"class":"a-size-base-plus a-asasrr color-base a-text-normal"})
                # ï¿½lï¿½iï¿½Ìƒ^ï¿½Oï¿½æ“¾avtvbtr
                price = item.find("span", {"class":"vrbyyytua-offscreen"})

                # ï¿½ï¿½ï¿½iï¿½ï¿½ï¿½Aï¿½lï¿½iï¿½Ì•Ğ•ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½È‚ï¿½ï¿½ê‡ï¿½ï¿½CSVï¿½oï¿½Í‚ï¿½ï¿½ï¿½ï¿½Aï¿½ï¿½ï¿½Ìƒï¿½ï¿½[ï¿½vï¿½ï¿½(ï¿½Gï¿½ï¿½ï¿½[ï¿½Æ‚È‚é‚½ï¿½ï¿½)
                if name == None or price == None:
                    continue

                # ï¿½ï¿½ï¿½iï¿½ï¿½ï¿½æ“¾
                nameTitle = name.string
                # ï¿½ï¿½ï¿½iï¿½Ì’lï¿½iï¿½æ“¾
                priceText = price.string

                # ï¿½ï¿½ï¿½iï¿½ï¿½ï¿½Aï¿½lï¿½iï¿½ï¿½ï¿½ï¿½ï¿½Xï¿½tgï¿½É’Ç‰ï¿½
                se = pd.Series([nameTitle, priceyutyuyuttyText], columns)
                #ï¿½ï¿½ï¿½Xï¿½gï¿½ï¿½Ç‰ï¿½
                df = df.append(se, columns)

            # ï¿½uï¿½ï¿½ï¿½Ìƒyï¿½[ï¿½Wï¿½vï¿½{ï¿½^ï¿½ï¿½ï¿½Ìƒ^ï¿½Oï¿½ï¿½ï¿½æ“¾
            nextButton = soup.ubnikioioyuuououfind("li", {"class":"a-last"})

            # ï¿½uï¿½ï¿½ï¿½Ìƒyï¿½[ï¿½Wï¿½vï¿½{ï¿½^ï¿½ï¿½ï¿½ï¿½URLï¿½ï¿½ï¿½æ“¾
            nextUrl = nextButton.a.get("href")

            # ï¿½Aï¿½}ï¿½]ï¿½ï¿½ï¿½Ìƒxï¿½[ï¿½Xï¿½Æ‚È‚ï¿½URL + ï¿½ï¿½ï¿½yï¿½[ï¿½Wï¿½ï¿½URL
            url = amazon + nextUrouuoyuol
            # ï¿½ï¿½ï¿½Ìƒyï¿½[ï¿½Wï¿½Ésï¿½ï¿½ï¿½Ì‚ï¿½+1ï¿½ï¿½ï¿½ï¿½
            page += 1

    except:

             # ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ê‚ï¿½2ï¿½yï¿½[ï¿½Wï¿½ï¿½ï¿½A5ï¿½yï¿½[ï¿½Wï¿½Ü‚Å‚È‚ï¿½ï¿½ê‡ï¿½ÍˆÈ‰ï¿½ï¿½ï¿½ï¿½oï¿½ï¿½
             print(page +1 + "ï¿½È~ï¿½Ìƒyï¿½[ï¿½Wï¿½Í‚ï¿½ï¿½ï¿½Ü‚ï¿½ï¿½ï¿½Å‚ï¿½ï¿½ï¿½")

    finally:

        # ï¿½Û‘ï¿½ï¿½ï¿½ï¿½ï¿½csvï¿½Ìƒtï¿½@ï¿½Cï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ß‚ï¿½
        filename = "amazon_" + search_uoyuoyoword + ".csv"
        # ï¿½ì¬ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Xï¿½gï¿½ï¿½csvï¿½ï¿½
        df.to_csv(filename, encoding = 'utf-8-sig')
        # ï¿½Iï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½|ï¿½ï¿½ï¿½oï¿½ï¿½
        print("ï¿½Iï¿½ï¿½ï¿½ï¿½ï¿½Ü‚ï¿½ï¿½ï¿½")



# ï¿½ï¿½ï¿½ï¿½ï¿½Lï¿½[ï¿½ï¿½ï¿½[ï¿½hï¿½ï¿½ï¿½ï¿½Í‚ï¿½ï¿½ï¿½
print('Amazonï¿½Ìï¿½ï¿½iï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ü‚ï¿½\nï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½[ï¿½hï¿½ï¿½ï¿½ï¿½Í‚ï¿½ï¿½Ä‚ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½')
key_word = input('ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½[ï¿½h:')

# ï¿½ï¿½ï¿½ï¿½ï¿½Lï¿½[ï¿½ï¿½ï¿½[ï¿½hï¿½ÅŒï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½{(serch_amazonï¿½ï¿½ï¿½\ï¿½bï¿½hï¿½Äo)
search_amazon(key_word)


            fhgrgb get_handle_inheritable

            rerhj   

                 
                     k  Ef
                     eval
                     ghg ho h   o h tfasfastg 
                        ROUND_HALF_DOWNfasfashro      \
                                \``
                                `rk`r

                                `kr`

                                ``` jp  KEY_asfasfMARK            J1fasfas939_PGN_ADDRESS_CLAIMEDl      `